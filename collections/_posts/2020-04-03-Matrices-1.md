---
layout: post-page
categories: [Learn, Матрицы - Основные определения]
---

## Векторные пространства строк и столбцов

----

*2.1 в первой книжке кострикина*

*определение векторного (линейного) пространства, его аксиомы, следствия из них, линейная комбинация и линейная оболочка, свойства линейных оболочек (альтернативное определение линейной оболочки множества векторов), пересечение/объединение линейных оболочек*

*линейная (не)зависимость, свойства линейной независимости (линейная зависимость части системы векторов, линейная зависимость <=> один вектор можно выразить через остальные, добавление вектора к линейной не/зависимой системе векторов)*

*базис линейной оболочки, стандартный базис, единственность разложения вектора по базису, базис - наибольший линейно независимый набор векторов, существование базиса и размерность линейной оболочки (независимость от базиса и то, что размерность линейных оболочек в R^n не может быть больше n)*

----

<br>

### Какие-то общие штуки

**Векторное пространство строк.** Множество $\mathbb{R}^n$ называется **векторным пространством** длины $n$ над $\mathbb{R}$. Элементы векторного пространства называются **векторами**. Векторное пространство рассматривается вместе с операциями **сложения векторов** (просто по-элементно) и **умножения на скаляры** (**скаляр** — в данном случае элемент $\mathbb{R}$). По сути векторы являются $1 \times n$ матрицами. Вот определения операций:

$$
X + Y = (x_1 + y_1, \dots, x_n + y_n) \\
\lambda X = (\lambda x_1, \dots, \lambda x_n)
$$

Нулевой вектор $(0, \dots, 0)$ будет обозначаться просто как $0$.

**Векторное (линейное) пространство** $(\mathbb{R}, \mathbb{R}^n)$ определяется с помощью следующих **аксиом**:

1. $X + Y = Y + X$ — коммутативность для сложения.
2. $(X + Y) + Z = X + (Y + Z)$ — ассоциативность для сложения.
3. $\exists 0 \in \mathbb{R}^n: X + 0 = X,\, \forall X \in \mathbb{R}^n$ — существование нулевого элемента по сложению (единственность выводится).
4. $\forall X \,\, \exists (-X) \in \mathbb{R}^n : X + (-X) = 0$ — существование обратного по сложению (единственность выводится).
5. $\exists 1 \in \mathbb{R} : 1X = X, \forall X \in \mathbb{R}^n$ — существование нейтрального по умножению на скаляр (единственность выводится).
6. $(\alpha\beta)X = \alpha(\beta X)$ — ассоциативность умножения на скаляр.
7. $(\alpha + \beta)X = \alpha X + \beta X$ — дистрибутивность.
8. $\alpha(X + Y) = \alpha X + \alpha Y$ — другая дистрибутивность.

----

<br>

**Линейные комбинации и линейная оболочка.** Вектор $X = \alpha_1 X_1 + \dots + \alpha_k X_k$ называется **линейной комбинацией векторов** $\{X_i\}$ с коэффициентами $\{\alpha_i\}$. **Линейной оболочкой** называется множество всех линейных комбинаций заданной системы векторов $X_1, \dots, X_k$ и обозначается как $\left<X_1, \dots, X_k\right>$. Очевидно, линейная оболочка замкнута относительно операций сложения векторов и умножения на скаляр.

Под $\left<S\right>$, где $S \subset \mathbb{R}^n$, подразумевается совокупность всех линейных комбинаций конечных систем векторов из $S$ (короче, берутся все возможные конечные подмножества векторов из $S$, и берётся совокупность их линейных оболочек).

**Свойства линейных оболочек:**

- Если $V$ — линейная оболочка, то $\left< V \right> = V$ (следует из замкнутости линейных оболочек относительно сложения и умножения на скаляр).

- Если $V$ — какая-то линейная оболочка, то $S \subset V \implies \left<S\right> \subset V$ (тоже следует из замкнутости относительно сложения и умножения).

- Альтернативное определение линейной оболочки: $\left< S \right> = \cap_{S \subset V} V$, где $V$ — это произвольные линейные оболочки.

  Пусть $X \in \left<S\right> \subset V,\, \forall V : S \subset V$, из этого следует вложенность в одну сторону (следует из предыдущего свойства). А в обратную сторону не знаю, как доказывать, но, видимо, это очевидно? Можно доказать, что **пересечение линейных оболочек является линейной оболочкой**: $X,Y \in \cap V \implies \alpha X + \beta Y \in \cap V,\, \forall \alpha,\beta \in \mathbb{R}$, потому что $X,Y \in V$ для каждой линейной оболочки, содержащей $S$, и линейные оболочки замкнуты относительно основных операций, так что они остаются внутри.

  При этом **объединение линейных оболочек в общем случае линейной оболочкой не является**, потому что линейная комбинация элементов из разных линейных оболочек может вылезти куда угодно. Например, если взять линейные оболочки $U = \{(\lambda,0) \mid \lambda \in \mathbb{R}\}$ и $V = \{(0, \lambda) \mid \lambda \in \mathbb{R}\}$, то их объединение линейной оболочкой не будет: $(1,0) \in U,\,\, (0, 1) \in V$, но при этом $(1, 1) \not \in U \cup V$.

----

<br>

**Линейная зависимость.** Система векторов $X_1, \dots, X_k$ называется **линейно зависимой**, если найдутся $k$ *одновременно не равных нулю* скаляров $\alpha_1, \dots, \alpha_k$ таких, что $\alpha_1 X_1 + \dots + \alpha_k X_k = 0$. Вот это последнее равенство — это **линейная зависимость** векторов, и, если коэффициенты не равны нулю, то будем говорить, что эта зависимость **нетривиальна**.

**Примеры:**

- Набор **единичных векторов** $E_{(1)} = (1, 0, \dots, 0), E_{(2)} = (0, 1, 0, \dots, 0),\dots,E_{(n)} = (0, 0, \dots,0,  1)$ всегда линейно независим, иначе нельзя составить такую линейную комбинацию, чтобы получился нулевой вектор.
- Система из одного *ненулевого* вектора тоже всегда линейно независима.

**Утверждения, связанные с линейной независимостью:**

- **Система векторов с линейно зависимой подсистемой сама будет линейно зависима.**

  Ну, тут очевидно, достаточно выставить правильные коэффициенты в линейной комбинации для линейно зависимой подсистемы, а остальные можно просто обнулить.

- **Любая часть линейно независимой системы векторов линейно независима.**

  Если предположить обратное, то из этого будет следовать линейная зависимость всей системы.

- **Система векторов является линейно зависимой тогда и только тогда, когда хотя бы один из векторов системы может быть выражен линейной комбинацией других.**

  Очевидно, если система векторов линейно зависима, то есть нетривиальная нулевая линейная комбинация:
  
  $$
  \alpha_1 X_1 + \dots + \alpha_k Xk = 0,\, \alpha_j \not = 0 \\
  X_j = -\frac{\alpha_1}{\alpha_j}X_1 + \dots + \widehat{X_j} + \dots -\frac{\alpha_k}{\alpha_j} X_k \\
  $$
  
  (Вот эта запись с шапочкой означает, что $j$-ый элемент пропускается. Иначе можно было бы написать левый и правый от пропускаемого элементы, но это слишком громоздкая запись.)

  Ну, и наоборот, если какой-то из векторов выражается через другие, то: либо он выражается просто как $X_k = 0 X_1 + \dots\ + \widehat{X_j} + \dots + 0X_k = 0$ — тогда система векторов будет линейно зависимой (потому что любая система, в которой есть хотя бы один нулевой вектор, будет линейно зависимой). Если же выражается нетривиально, то, ну, просто понятно всё.

- **Если $X_1,\dots,X_k$ линейно независимы, а $X_1,\dots,X_k,X$ линейно зависимы (просто добавили к системе ещё какой-то вектор), то $X$ выражается через линейную комбинацию векторов $X_1,\dots,X_k$.**

  Для доказательства достаточно рассмотреть нетривиальную линейную комбинацию:
  
  $$
  \alpha_1 X_1 + \dots + \alpha_k X_k + \alpha X = 0
  $$
  
  Если $\alpha \not = 0$, то достаточно просто перенести $X$ направо и разделить всё выражение на $\alpha$. Если же $\alpha = 0$, то это бы означало, что и $\alpha_1 = 0, \dots,\,\alpha_k = 0$ в силу линейной независимости $X_1, \dots, X_k$, и это всё противоречит с линейной зависимостью $X_1, \dots, X_k, X$.
  
- **Если $X_1, \dots, X_k$ линейно независимы, и нельзя выразить $X_{k+1}$ через эти вот векторы $X_1, \dots, X_k$, то система векторов $X_1, \dots, X_{k+1}$ тоже будет линейно независимой.**

  Потому что, будь они линейно зависимой системой, то по предыдущему утверждению это бы означало, что $X_{k+1}$ выражается через остальные векторы, а это противоречит условию.

----

<br>

**Базис. Размерность.** Пусть $V$ — линейная оболочка в $\mathbb{R}^n$, тогда система векторов $X_1, \dots, X_m$ называется **базисом** для $V$, если она линейно независима и её линейная оболочка совпадает с $V$ (иначе говоря, является **порождающей** для $V$). Базис полезен тем, что через него единственным образом через линейную комбинацию выражается любой вектор из $V$. То, что оно как-то выражается, — это очевидно (по определению), а единственность следует из линейной независимости:

$$
\text{Рассмотрим два разложения вектора } X \text{ по базису:} \\
X = \alpha_1 X_1 + \dots + \alpha_m X_m, \,\, X = \beta_1 X_1 + \dots + \beta_m X_m \\
(\alpha_1 - \beta_1) X_1 + \dots + (\alpha_m - \beta_m) X_m = 0 \implies \alpha_i = \beta_i,\forall i
$$

$\mathbb{R}^n$ — это, очевидно, тоже линейная оболочка единичных векторов. И эти единичные вектора также являются базисом $\mathbb{R}^n$ (порождающий плюс линейно независимый). $\{E_{(1)}, E_{(2)},\dots, E_{(n)}\}$ — **стандартный базис**, но **базис может не быть единственным**. Например, есть ещё вот такой базис:

$$
E'_{(1)} = E_{(1)} \\
E'_{(2)} = E_{(1)} + E_{(2)} \\
E'_{(3)} = E_{(1)} + E_{(2)} + E_{(3)} \\
\dots\\
E'_{(n)} = E_{(1)} + \dots + E_{(n)}
$$

(Ну, тут легко проверить то, что этот набор векторов порождающий и линейно независимый.)

----

<br>

**Лемма.** Пусть $V$ — линейная оболочка с базисом $X_1, \dots, X_m$. Тогда, если $Y_1, \dots, Y_k$ — линейно независимая система из векторов из $V$, то $m \geq k$. (То есть **базис — наибольший линейно независимый набор**.)

*Доказательство.* Для начала распишем векторы $\{Y_i\}$ как линейные комбинации базисных векторов:

$$
Y_1 = \alpha_{11} X_1 + \alpha_{12} X_2 + \dots + \alpha_{1m} X_m\\
\dots\\
Y_k = \alpha_{k1} X_1 + \alpha_{k2} X_2 + \dots + \alpha_{km} X_m
$$

Будем доказывать от противного: предположим, что $k \gt m$. Составим линейную комбинацию из векторов $\{Y_i\}$:

$$
x_1 Y_1 + \dots + x_k Y_k = [\text{раскладываем игреки по базису}] \\
= x_1(\alpha_{11} X_1 + \alpha_{12} X_2 + \dots + \alpha_{1m} X_m) + \dots + x_k (\alpha_{k1} X_1 + \alpha_{k2} X_2 + \dots + \alpha_{km} X_m)\\
= (\alpha_{11}x_1 + \dots + \alpha_{k1}x_k)X_1 + \dots + (\alpha_{1m}x_1 + \dots + \alpha_{km}x_k)X_m
$$

Попробуем приравнять значение этой линейной комбинации к нуль-вектору. Для этого придётся решить систему уравнений:

$$
\begin{cases}
	\alpha_{11}x_1 + \dots + \alpha_{k1}x_k = 0\\
	\dots\\
	\alpha_{1m}x_1 + \dots + \alpha_{km}x_k = 0
\end{cases}
$$

Так как мы приняли, что $k > m$ (то есть в данном случае у нас переменных больше, чем уравнений), то это означает, что после приведения к ступенчатому виду у нас будут свободные неизвестные, которые могут принимать произвольные значения, а, значит, будет ненулевое решение . То есть мы нашли способ нетривиально обнулить $x_1 Y_1 + \dots + x_k Y_k$, что противоречит с тем, что $\{Y_i\}$ — линейно независимый набор векторов по условию.

----

<br>

**Теорема.** Каждая *ненулевая* (содержащая по крайней мере один ненулевой вектор) линейная оболочка $V \subset \mathbb{R}^n$ обладает конечным базисом. При этом все базисы оболочки $V$ состоят из одинакового числа $m \leq n$ векторов (короче, **количество элементов в базисе не больше размерности R^n штуки, в которой находится линейная оболочка**), и это число обозначается как $\dim V := m$ и называется **размерностью линейной оболочки**.

*Доказательство.* По условию в $V$ есть хотя бы один ненулевой вектор, обозначим его за $X_1$. Предположим, что мы нашли линейно независимую систему векторов $X_1, \dots, X_k$ (по крайней мере можно взять один единственный $X_1$, он будет линейно независим сам по себе). Если линейная оболочка выбранного набора линейно независимых векторов $\left<X_1,\dots,X_k\right>$ *не совпадает* с $V$, то берём $X_{k+1} : X_{k + 1} \in V,\, X_{k+1} \not \in \left< X_1, \dots, X_k \right>$. И по теореме выше набор $X_1, \dots, X_{k+1}$ тоже будет линейно независимой (добавляем к линейно независимому набору вектор, который не выражается через эти векторы).

По предыдущей лемме любой линейно независимый набор в $V$ содержит не более, чем $n$ векторов (рассматриваем линейную оболочку $\mathbb{R}^n$, в которой у нас есть стандартный базис с $n$ элементами). Так что мы не сможем бесконечно добавлять новые векторы в систему, а это означает, что, рано или поздно, она станет максимальной/порождающей. Так доказали *существование базиса* для линейной оболочки.

Предположим, что $Y_1, \dots, Y_s$ — ещё один базис в $V$. Тогда $s \leq m$ по предыдущей лемме, так как базис — это линейно независимая штука. И наоборот, если подставить в лемму $\{X_i\}$ вместо $\{Y_i\}$, то, получится, что $m \leq s$. Из этого следует, что $m = s$, а, значит, мы можем корректно определить размерность линейной оболочки.

<br>

**Ранг системы векторов** в $\mathbb{R}^n$: $\{X_1, X_2,\dots\}$ определяется как размерность линейной оболочки, построенной на них:

$$
\text{rank} \{X_1, X_2,\dots \} := \dim\left<X_1, X_2, \dots\right>
$$

**Размерность линейной оболочки, состоящей только из нуль-вектора** принять считать равной нулю: $\dim V := 0,\,V = \{0\}$.

