---
layout: post-page
categories: [Learn, Матрицы - Основные определения]
---

## Ранг матрицы 

----

*2.2 в первом томе кострикина*

*определение решения системы линейных уравнений в терминах вот этих всех линейных оболочек, ранг матрицы по столбцам и по строкам, инвариантность рангов относительно элементарных преобразований, равенство рангов по строкам и столбцам, теорема кронекера-капелли*

----

<br>

### Опять решения систем линейных уравнений

**Альтернативное определение решения системы уравнений.** Пусть мы находимся в векторном пространстве $\mathbb{R}^m$ из столбцов $A^{(j)} = [a_{1j}, a_{2j},\dots, a_{mj}]$. (**Соглашения об обозначениях.** Столбцы обозначаем с индексом наверху, но, чтобы это не конфликтовало со степенью, засовываем индекс в скобки. Сами столбцы выписываем горизонтально, но в квадратных скобках.) Пусть у нас есть ещё один вектор из $\mathbb{R}^m$ $B = [b_1, b_2, \dots, b_m]$. **Нам нужно определить, принадлежит ли вектор $B$ линейной оболочке $V = \left<A_1, \dots, A_n\right>$, и через какие коэффициенты выражается $B$ через эти векторы.** По сути этот вопрос эквивалентен вопросу решения соответствующей системы уравнений:

$$
x_1 \left(\begin{matrix}a_{11}\\a_{21}\\ \vdots \\ a_{m1}\end{matrix} \right)
+ x_2 \left(\begin{matrix}a_{12}\\a_{22}\\ \vdots \\ a_{m2}\end{matrix} \right)
+ \dots
+ x_n \left(\begin{matrix}a_{1n}\\a_{2n}\\ \vdots \\ a_{mn}\end{matrix} \right)
= \left(\begin{matrix}b_{1}\\b_{2}\\ \vdots \\ b_{m}\end{matrix} \right)\\
$$

$$
(A \mid B) = \left(\begin{array}{cccc|c}
	a_{11} & a_{12} & \dots & a_{1n} & b_1 \\
	a_{21} & a_{22} & \dots & a_{2n} & b_2 \\
	\dots & \dots & \dots & \dots & \dots\\
	a_{m1} & a_{m2} & \dots & a_{mn} & b_m \\
\end{array}\right)
$$

----

<br>

### Ранг матрицы

Назовём **пространством столбцов прямоугольной** $m \times n$ **матрицы** $A$ линейную оболочку $V_v = \left<A^{(1)}, \dots, A^{(n)}\right>$ ("v" от *vertical*). Аналогичным образом вводится **пространство строк матрицы** $A$: $V_h$ ("h" от *horizontal*). Размерность $r_v(A) = \dim V_v$ будем называть **рангом по столбцам матрицы**, $r_h(A) = \dim V_h$ — **ранг по строкам матрицы**.

$$
r_v(A) = \text{rank}\{A^{(1)},A^{(2)}, \dots,A^{(n)}\} \\
r_h(A) = \text{rank}\{A_{(1)},A_{(2)}, \dots,A_{(m)}\}
$$

По аналогии с тем, как мы определили элементарные преобразования для системы линейных уравнений , можно определить их и для матрицы (первый тип — перестановка строк, второй тип — домножение строки на скаляр и прибавление её к другой строке).

**Лемма.** Если матрица $A'$ получена из матрицы $A$ путём конечной последовательности элементарных преобразований над строками, то имеют место равенства:

$$
r_v(A') = r_v(A)\\
r_h(A') = r_H(A)
$$

*Доказательство.* Для доказательства достаточно доказать, что равенства сохраняется после применения одного произвольного элементарного преобразования. Рассмотрим для начала *ранг по строкам матрицы*. Если мы поменяем какие-то две строки местами, то, очевидно, линейная пространство строк вообще никак не поменяется, потому что какая разница, в каком порядке они расположены. Теперь элементарное преобразование второго типа:

$$
A'_{(s)} = A_{(s)} + \lambda A_{(t)} \text{ - элементарное преобразование}\\
\left<A_{(1)}, \dots, A_{(s)} + \lambda A_{(t)}, \dots,A_{(t)},\dots,A_{(m)} \right> = \left<A_{(1)}, \dots, A_{(s)}, \dots,A_{(t)},\dots,A_{(m)} \right>
$$

Теперь рассмотрим *ранг по столбцам матрицы*. Для этого для начала докажем, что:

$$
\sum_{j = 1}^l \lambda_j A^{(j)} = 0 \iff \sum_{j = 1}^l \lambda_j A'^{(j)}
$$

Это очевидно из того, что мы уже доказали, что решения систем уравнений, полученных друг из друга элементарными преобразованиями, совпадают, причём с точностью до порядка значений неизвестных в решениях системы. Из этого следует, что если мы возьмём $l$ любых линейно независимых столбцов в матрице до преобразования, то после преобразования они останутся линейно независимыми. В том числе, если взять базис пространства столбцов до преобразования, то он останется базисом и после преобразования, что доказывает, что ранг не изменится после преобразований $\square$

(Не изменится, потому что, если бы он увеличился, то можно было найти большую линейно независимую порождающую систему до преобразования. А уменьшиться он не может, потому что он как минимум остаётся таким же.)

----

<br>

**Теорема.** Для любой прямоугольной $m \times n$ матрицы $A$ справедливо равенство $r_h(A) = r_v(A)$. Это число называется рангом матрицы $A$ и обозначается как $\text{rank}(A)$.

*Доказательство.* Уже разобрались с тем, что любую матрицу (систему линейных уравнений) можно привести к ступенчатому виду:

![image-20200404190153356](/assets/images/math.assets/image-20200404190153356.png)



По предыдущей лемме после преобразования ни горизонтальный ранг матрицы, ни вертикальный, не изменятся. Столбцы матрицы $1,k,l,\dots,s$ будем называть **базисными столбцами**. (То есть выбрали все столбцы, в которых разное количество ненулевых значений.) Такой набор из $r$ столбцов (я на некоторое время завис на этом, потому что не сразу увидел, что базисных столбцов там действительно $r$ штук) будет линейно независимым:

$$
\lambda_1 A^{(1)} + \lambda_k A^{(k)} + \lambda_l A^{(l)} + \dots + \lambda_s A^{(s)} = 0 \\
A^{(1)} = [a_{11},0,\dots,0],\,\,A^{k} = [a_{1k},a_{2k},0,\dots,0],\dots,A^{(s)} = [a_{1s},\dots,a_{rs}] \\
\implies \lambda_s a_{rs} = 0,\,\, \dots,\,\,\lambda_l a_{3l} = 0,\,\,\lambda_l a_{3l} = 0,\,\,\lambda_k a_{2k} = 0,\,\,\lambda_1 a_{11} = 0
$$

Из этого следует, что $r_v(A) \geq r$. Однако $\left<A^{(1)},A^{(k)},\dots,A^{(s)}\right> = \mathbb{R}^r$ (ну, не совсем так, но, если отождествить $(a_1, \dots,a_r) = (a_1, \dots, a_r, 0, \dots, 0)$, то оно будет так. Ну, из этого следует, что любой линейно независимый набор в линейной оболочке этих базисных столбцов имеет $\leq r$ элементов. Так что $r_v(A) = r$.

Аналогично получается, что первые $r$ строк в матрице $A$ линейно независимы, из чего будет следовать, что $r_h(A) \geq r$. И при этом пространство строк таблицы порождается только вот этими $r$ ненулевыми первыми строками. То есть это базис по определению, а значит, $r_h(A) = r$.

Так что получается: $r_h(A) = r = r_v(A)$. И это равенство для преобразованной матрицы, но по предыдущей лемме элементарные преобразования не меняют ранг матрицы по строкам/столбцам, так что равенство рангов будет верно и для матрицы до преобразования $\square$

----

<br>

Таким образом, вывели то, что число главных неизвестных равно рангу матрицы.

**Теорема Кронекера-Капелли.** Система линейных уравнений совместна (имеет хотя бы одно решение) тогда и только тогда, когда ранг матрицы системы совпадает с рангом расширенной матрицы системы.

*Доказательство* ($\implies$). Если расписать систему линейных уравнений по столбцам, то совместность системы трактуется как вопрос о том, можно ли представить вектор $B$ как линейную комбинацию векторов-столбцов. Если такое представление возможно, то: $B \in \left<A^{(1)}, \dots, A^{(n)}\right>$ и $\text{rank}(A^{(1)}, \dots, A^{(n)}) = \text{rank}(A^{(1)},\dots,A^{(n)},B)$ (потому что добавление вектора, который линейно выражается через остальные не меняет базиса) $\square$

*Доказательство* ($\impliedby$). Теперь предположим, что ранги матриц $(A \mid B)$ и $A$ совпадают. Допустим, что $\{A^{(j_1)}, \dots, A^{(j_r)}\}$ — это какой-то базисный набор столбцов матрицы $A$. Если добавить к ней любой один вектор (в том числе $B$), то набор станет линейно зависимым, так что можно будет выразить $B$ через выбранные базисные векторы, что эквивалентно разрешимости системы $\square$

<br>

<br>

## Линейные отображения. Действия с матрицами

----

*2.3 в первом томе кострикина*

*определение линейного отображения, матрица линейного отображения, линейная комбинация линейных отображений (то, что это линейное отображение, и формула для матрицы), композиция линейных отображений, произведение матриц, свойства произведения матриц*

----

<br>

### Матрицы и отображения

**Определение линейного отображения.** Пусть $\mathbb{R}^n$ и $\mathbb{R}^m$ — векторные пространства столбцов, $A = (a_{ij})$ — матрица размера $m \times n$. Определим отображение $\phi_A: \mathbb{R}^n \rightarrow \mathbb{R}^m$, которое отображает любой вектор $X = [x_1, x_2, \dots, x_n] \in \mathbb{R}^n$ следующим образом:

$$
\phi_A(X) = x_1 A^{(1)} + x_2 A^{(2)} + \dots + x_n A^{(n)}
$$

Ну, или ещё можно вот так определить (вектор $X$ отображается в вектор $Y$):

$$
\left(\begin{matrix}
	y_1 \\ \vdots \\ y_m
\end{matrix}\right)
= \left( \begin{matrix}
	a_{11} & \dots & a_{1n} \\
	\dots & \dots & \dots \\
	a_{m1} & \dots & a_{mn}
\end{matrix}\right)
\left(\begin{matrix}
	x_1 \\ \vdots \\ x_n
\end{matrix}\right)
= \left(\begin{matrix}
	a_{11} x_1 + \dots + a_{1n}x_n \\
	\vdots \\
	a_{m1} x_1 + \dots + a_{mn}x_n
\end{matrix}\right)
$$

Можно вывести вот такие **свойства** отображения $\phi_A$:

- $\phi_A(X' + X'') = \sum_{i = 1}^n (x_i' + x_i'') A^{(i)} = \sum_{i = 1}^n x_i'' A^{(i)} + \sum_{i = 1}^n x_i'' A^{(i)} = \phi_A(X') + \phi(X'')$ — *аддитивность*.

- $\phi_A(\lambda X) = \sum_{i = 1}^n (\lambda x_i) A^{(i)} = \lambda \phi_A(X)$ — *не знаю, как такое называется*.

Теперь попробуем подойти с другой стороны: допустим, у нас есть произвольное отображение $\phi: \mathbb{R}^n \rightarrow \mathbb{R}^m$, которое обладает вышеуказанными свойствами. Из этих свойств следует вот это равенство (раскладываем аргумент $X$ по базисным векторам):

$$
\phi(X) = \phi(\sum_{i = 1}^n x_i E^{(i)}) = \sum_{i + 1}^n x_i \phi(E^{(i)})
$$

То есть отображение с такими свойствами **полностью определяется своими значениями на базисных векторах**. Если взять в качестве этих значений столбцы матрицы $A$: $\phi(E^{(i)}) := A^{(i)}$, то мы получим как раз определение отображения $\phi_A$.

Отображение $\phi = \phi_A : \mathbb{R}^n \rightarrow \mathbb{R}^m$, которое обладает свойствами $\phi(X_1 + X_2) = \phi(X_1) + \phi(X_2)$ и $\phi(\lambda X) = \lambda \phi(X)$, называется **линейным отображением** из $\mathbb{R}^n$ в $\mathbb{R}^m$. Если $n=m$, то его ещё называют **линейным преобразованием**. Матрица $A$ называется **матрицей линейного отображения**. (Если матрицы линейных отображений совпадают, то совпадают и соответствующие им линейные отображения, и наоборот, то есть **есть взаимно однозначное соответствие между матрицами $m \times n$ и линейными отображениями из $\mathbb{R}^n$ в $\mathbb{R}^m$**.)

В частности можно говорить о **линейных функциях** от $n$ переменных, которые определяются как линейные отображения из $\mathbb{R}^n$ в $\mathbb{R}$ и задаются $n$ скалярами $a_1,\dots,a_n$:

$$
\phi(X) = \phi(x_1,\dots,x_n) = a_1 x_1 + \dots + a_n x_n
$$

**Линейная комбинация линейных отображений является линейным отображением** с матрицей, равной линейной комбинации матриц исходных отображений. (Жесть ужасно сложно звучит, но на деле это выглядит довольно очевидной штукой.) То, что это линейное отображение, проверяется просто по определению этих двух свойств. Пусть $C$ — матрица отображения $\phi$, тогда:

$$
C^{(i)} = \phi(E^{(i)}) = \alpha \phi_A(E^{(i)}) + \beta \phi_B(E^{(i)}) = \alpha A^{(i)} + \beta B^{(i)} \\
\implies C = \alpha A + \beta B
$$

----

<br>

### Произведение матриц

По аналогии с тем, как линейная комбинация линейных отображений является линейным отображением, **композиция линейных отображений — это тоже линейное отображение**. Это легко проверить. И тут интереснее то, какая получается матрица у композиции отображений:

![image-20200406020246765](/assets/images/math.assets/image-20200406020246765.png)

<br>

Матрицу композиции отображений будем называть **произведением матриц** $A$ и $B$. При этом смысл произведения матриц $AB$ имеет смысл только, когда число столбцов первой матрицы равно числу строк во второй матрице (это как раз связано с тем, как мы определили произведение матриц через композицию отображений). А число строк результирующей матрицы равно числу строк в первой матрице, число столбцов равно числу столбцов во второй матрице.

**Свойства умножения матриц.** Точно так же, как композиция отображений **не является коммутативной**, произведение матриц тоже не коммутативно. Но есть **ассоциативность**, как и у, опять же, композиции. То же самое можно проверить, приведя контр-пример, и проведя ту пые вычисления. Также есть **свойство дистрибутивности**: $(A + B) C = AC + BC$ и $A(B + C) = AB + AC$. Доказывается просто, если расписать произведение матриц по формуле:

$$
\sum_{k =  1}^s (a_{ik} + b_{ik}) c_{kj} = \sum_{k =  1}^s a_{ik} c_{kj} + \sum_{k =  1}^s b_{ik} c_{kj}
$$

----

<br>

### Транспонирование матриц

**Транспонирование матриц** — это замена в матрице строк на столбцы, а столбцов на строки. Выглядит вот так:

$$
A = \left(\begin{matrix}
	a_{11} & a_{12} & \dots & a_{1m} \\
	a_{21} & a_{22} & \dots & a_{2m} \\
	\dots & \dots &\dots &\dots \\
	a_{n1} & a_{n2} & \dots & a_{nm}
\end{matrix}\right),\,\,

A^T = \left(\begin{matrix}
	a_{11} & a_{21} & \dots & a_{n1} \\
	a_{12} & a_{22} & \dots & a_{n2} \\
	\dots & \dots &\dots &\dots \\
	a_{1m} & a_{2m} & \dots & a_{nm}
\end{matrix}\right)
$$

(Мне вообще проще думать об этом не как о перестановке столбцов и строк, а как об отражении матрицы относительно диагонали, продлённой за границы матрицы, если это необходимо. Эти все дурацкие столбцы и строки вообще не укладываются в голову. Ну, и так получается, что если $(b_{ij}')$ — транспонированная матрица, то $b_{ij}' = b_{ji}$.)

**Свойства транспонирования матриц:**

- Очевидно, из матрицы $n \times m$ после транспонирования получается матрица $m \times n$.

- $(A^T)^T = A$

- $(A + B)^T = A^T + B^T$

- $(\lambda A)^T = \lambda A^T$

- $(AB)^T = B^T A^T$. Проверяется просто по определению:

  $$
  C = AB,\,\, D = B^T A^T\\
  c_{ij} = \sum_{k = 1}^n a_{ik} b_{kj},\,\, d_{ji} = \sum_{k=1}^n b'_{jk} a'_{ki} = \sum_{k = 1}^n a_{ik} b_{kj}
  $$
  
- Ну, и в целом получается, что $(A_1 A_2 \dots A_n)^T = A_n^T A_{n-1}^T \dots A_1^T$.

- $\text{rank}A^T = \text{rank}A$ (просто из того, что ранг по столбцам равен рангу по строкам).
